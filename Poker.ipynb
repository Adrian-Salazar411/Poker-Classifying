{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split, GroupKFold, GroupShuffleSplit,StratifiedShuffleSplit\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from bayes_opt import BayesianOptimization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('poker-hand-testing.data')\n",
    "train = pd.read_csv('poker-hand-training-true.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Hands')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#From the count plot we can see that there is a really big class imbalance in the training data set.\n",
    "#In order to deal with this, a stratifiedshuffle split will be used on our dataset to ensure that \n",
    "#at least some of the samples make it into both the training and validation sets.\n",
    "sns.countplot('9',data=train)\n",
    "plt.xlabel('Hands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.499540\n",
       "1    0.423807\n",
       "2    0.048223\n",
       "3    0.020513\n",
       "4    0.003719\n",
       "5    0.002159\n",
       "6    0.001439\n",
       "7    0.000240\n",
       "8    0.000200\n",
       "9    0.000160\n",
       "Name: 9, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['9'].value_counts()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['9']\n",
    "X = train.drop('9',axis=1)\n",
    "folds = StratifiedShuffleSplit(n_splits=4, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "        \n",
    "    clf = lgb.LGBMClassifier(**params, n_estimators=20000, nthread=-1)\n",
    "\n",
    "    test_pred_proba = np.zeros((train.shape[0], 10))\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train, y)):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params, n_estimators = 10000, n_jobs = -1)\n",
    "        model.fit(X_train, y_train, \n",
    "                eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='multi_logloss',\n",
    "                verbose=False, early_stopping_rounds=200)\n",
    "\n",
    "        y_pred_valid = model.predict_proba(X_valid)\n",
    "\n",
    "        test_pred_proba[valid_idx] = y_pred_valid\n",
    "\n",
    "    return accuracy_score(y_valid, y_pred_valid.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'colsample_bytree': (0.6, 0.8),\n",
    "#       'learning_rate': (.0001, .5), \n",
    "#       'num_leaves': (2, 124), \n",
    "#       'subsample': (0.6, 1), \n",
    "#       'max_depth': (3, 120), \n",
    "#       'reg_alpha': (.001, 15.0), \n",
    "#       'reg_lambda': (.001, 15.0), \n",
    "#       'min_split_gain': (.001, .03),\n",
    "#       'min_child_weight': (2, 80)}\n",
    "\n",
    "# bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "# bo.maximize(init_points=5, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = bo.max['params']\n",
    "# params['num_leaves'] = 4\n",
    "# params['max_depth'] =5\n",
    "# test_pred_proba = np.zeros((train.shape[0], 10))\n",
    "# folds = StratifiedShuffleSplit(n_splits=4, test_size=0.2)\n",
    "# for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train, y)):\n",
    "#         X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "#         y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        \n",
    "#         model = lgb.LGBMClassifier(**params, n_estimators = 10000, n_jobs = -1)\n",
    "#         model.fit(X_train, y_train, \n",
    "#                 eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='multi_logloss',\n",
    "#                 verbose=False, early_stopping_rounds=200)\n",
    "\n",
    "#         y_pred_valid = model.predict_proba(X_valid)\n",
    "\n",
    "#         test_pred_proba[valid_idx] = y_pred_valid\n",
    "\n",
    "#         print(accuracy_score(y_valid, y_pred_valid.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = test['0']\n",
    "# X = test.drop('0',axis=1)\n",
    "# test_pred_proba = np.zeros((test.shape[0], 10))\n",
    "# y_pred_valid = model.predict_proba(X)\n",
    "# #test_pred_proba[valid_idx] = y_pred_valid\n",
    "# print(accuracy_score(y, y_pred_valid.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y,y_pred_valid.argmax(1))\n",
    "# df_cm = pd.DataFrame(cm)\n",
    "# plt.figure(figsize = (15,10))\n",
    "# sns.heatmap(df_cm, annot=True, cmap = 'magma', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Bayesian Optimization, the this lightGBM model could only predict ~65.5% accuracy\n",
    "#This could be because random forest struggles with fitting models that have \n",
    "#high class imbalances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.softmax1 = nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.softmax1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(10,16,10)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X.values.astype(np.float32))\n",
    "y = torch.from_numpy(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  2.328730344772339\n",
      "epoch:  1  loss:  2.3209283351898193\n",
      "epoch:  2  loss:  2.312237024307251\n",
      "epoch:  3  loss:  2.302582025527954\n",
      "epoch:  4  loss:  2.2919273376464844\n",
      "epoch:  5  loss:  2.280221939086914\n",
      "epoch:  6  loss:  2.2675318717956543\n",
      "epoch:  7  loss:  2.254004716873169\n",
      "epoch:  8  loss:  2.239858388900757\n",
      "epoch:  9  loss:  2.225396156311035\n",
      "epoch:  10  loss:  2.2110037803649902\n",
      "epoch:  11  loss:  2.1970131397247314\n",
      "epoch:  12  loss:  2.1837239265441895\n",
      "epoch:  13  loss:  2.1713805198669434\n",
      "epoch:  14  loss:  2.1601040363311768\n",
      "epoch:  15  loss:  2.1498968601226807\n",
      "epoch:  16  loss:  2.140781879425049\n",
      "epoch:  17  loss:  2.1326687335968018\n",
      "epoch:  18  loss:  2.125448226928711\n",
      "epoch:  19  loss:  2.119048833847046\n",
      "epoch:  20  loss:  2.113369941711426\n",
      "epoch:  21  loss:  2.1083109378814697\n",
      "epoch:  22  loss:  2.103803873062134\n",
      "epoch:  23  loss:  2.099762439727783\n",
      "epoch:  24  loss:  2.0961227416992188\n",
      "epoch:  25  loss:  2.0928597450256348\n",
      "epoch:  26  loss:  2.0899014472961426\n",
      "epoch:  27  loss:  2.0872154235839844\n",
      "epoch:  28  loss:  2.084784507751465\n",
      "epoch:  29  loss:  2.0825514793395996\n",
      "epoch:  30  loss:  2.080500364303589\n",
      "epoch:  31  loss:  2.078620195388794\n",
      "epoch:  32  loss:  2.0768918991088867\n",
      "epoch:  33  loss:  2.0752968788146973\n",
      "epoch:  34  loss:  2.073828935623169\n",
      "epoch:  35  loss:  2.072445869445801\n",
      "epoch:  36  loss:  2.0711700916290283\n",
      "epoch:  37  loss:  2.069988965988159\n",
      "epoch:  38  loss:  2.0688672065734863\n",
      "epoch:  39  loss:  2.0678186416625977\n",
      "epoch:  40  loss:  2.0668253898620605\n",
      "epoch:  41  loss:  2.0659196376800537\n",
      "epoch:  42  loss:  2.0650599002838135\n",
      "epoch:  43  loss:  2.064241647720337\n",
      "epoch:  44  loss:  2.0634608268737793\n",
      "epoch:  45  loss:  2.0627353191375732\n",
      "epoch:  46  loss:  2.062051773071289\n",
      "epoch:  47  loss:  2.0613973140716553\n",
      "epoch:  48  loss:  2.0607757568359375\n",
      "epoch:  49  loss:  2.0601911544799805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(50):\n",
    "    # Forward Propagation\n",
    "    y_pred = model(X_train)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.from_numpy(test.drop('0',axis=1).values.astype(np.float32))\n",
    "y_test = torch.from_numpy(test['0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-742409076f26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "torch.Tensor.numpy(torch.max(y_pred,1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
